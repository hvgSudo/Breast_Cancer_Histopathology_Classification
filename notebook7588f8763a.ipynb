{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khal-drog0/Breast_Cancer_Histopathology_Classification/blob/main/notebook7588f8763a.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q kaggle"
      ],
      "metadata": {
        "id": "ldYMw_5YM0HQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "0M6nCCGbNGA0",
        "outputId": "471b0ba2-2fa6-4b9d-d0ec-5fb8929b47f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2b5f0f47-72e3-4a37-8b73-e4c307b60676\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2b5f0f47-72e3-4a37-8b73-e4c307b60676\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m   \"\"\"\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    121\u001b[0m   result = _output.eval_js(\n\u001b[1;32m    122\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m--> 123\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m    124\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "nMwqhx7CNU72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json /root/.kaggle"
      ],
      "metadata": {
        "id": "y7BvGqAfNjI6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! chmod 600 /root/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "v0lwz02XNo-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d paultimothymooney/breast-histopathology-images"
      ],
      "metadata": {
        "id": "Jabdnpw6M4Au"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip breast-histopathology-images.zip"
      ],
      "metadata": {
        "id": "DtxMf79ROlSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T04:53:13.197656Z",
          "iopub.status.busy": "2022-03-24T04:53:13.197335Z",
          "iopub.status.idle": "2022-03-24T04:53:13.201253Z",
          "shell.execute_reply": "2022-03-24T04:53:13.200336Z",
          "shell.execute_reply.started": "2022-03-24T04:53:13.197624Z"
        },
        "trusted": true,
        "id": "b23MIjBrMpVW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T04:53:13.282126Z",
          "iopub.status.busy": "2022-03-24T04:53:13.281818Z",
          "iopub.status.idle": "2022-03-24T04:54:23.204902Z",
          "shell.execute_reply": "2022-03-24T04:54:23.204150Z",
          "shell.execute_reply.started": "2022-03-24T04:53:13.282097Z"
        },
        "trusted": true,
        "id": "uwlSdefGMpVX"
      },
      "outputs": [],
      "source": [
        "images = glob('IDC_regular_ps50_idx5/**/*.png', recursive = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T04:54:23.208419Z",
          "iopub.status.busy": "2022-03-24T04:54:23.208210Z",
          "iopub.status.idle": "2022-03-24T04:54:23.441418Z",
          "shell.execute_reply": "2022-03-24T04:54:23.440646Z",
          "shell.execute_reply.started": "2022-03-24T04:54:23.208394Z"
        },
        "trusted": true,
        "id": "t9QqFljgMpVY"
      },
      "outputs": [],
      "source": [
        "class0 = [] # 0 = no cancer\n",
        "class1 = [] # 1 = cancer\n",
        "\n",
        "for filename in images:\n",
        "    # copying class 0 and class 1 files to class0 and class1 lists,\n",
        "    # respectively\n",
        "    if filename.endswith(\"class0.png\"):\n",
        "        class0.append(filename)\n",
        "    else:\n",
        "        class1.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T04:54:23.442869Z",
          "iopub.status.busy": "2022-03-24T04:54:23.442547Z",
          "iopub.status.idle": "2022-03-24T04:54:23.449547Z",
          "shell.execute_reply": "2022-03-24T04:54:23.448842Z",
          "shell.execute_reply.started": "2022-03-24T04:54:23.442831Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALDPqVWnMpVY",
        "outputId": "9de3ee23-b422-4868-c61f-5bd2226bb606"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "class0 length: 198738\n",
            "class1 length: 78786\n"
          ]
        }
      ],
      "source": [
        "print('class0 length:', len(class0))\n",
        "print('class1 length:', len(class1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T04:54:23.452282Z",
          "iopub.status.busy": "2022-03-24T04:54:23.451554Z",
          "iopub.status.idle": "2022-03-24T04:54:23.634498Z",
          "shell.execute_reply": "2022-03-24T04:54:23.633811Z",
          "shell.execute_reply.started": "2022-03-24T04:54:23.452244Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIVGUXoXMpVZ",
        "outputId": "006ba874-84bc-4588-d8a3-7d8e569f26f6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78786"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "sampled_class0 = random.sample(class0, 78786)\n",
        "sampled_class1 = random.sample(class1, 78786)\n",
        "len(sampled_class0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T04:54:23.635890Z",
          "iopub.status.busy": "2022-03-24T04:54:23.635646Z",
          "iopub.status.idle": "2022-03-24T04:54:23.642432Z",
          "shell.execute_reply": "2022-03-24T04:54:23.641753Z",
          "shell.execute_reply.started": "2022-03-24T04:54:23.635856Z"
        },
        "trusted": true,
        "id": "m0M_1GPCMpVZ"
      },
      "outputs": [],
      "source": [
        "from matplotlib.image import imread\n",
        "import cv2\n",
        "\n",
        "def get_image_arrays(data, label):\n",
        "    img_arrays = []\n",
        "    for i in data:\n",
        "        if i.endswith('.png'):\n",
        "            img = cv2.imread(i ,cv2.IMREAD_COLOR)\n",
        "            img_sized = cv2.resize(img, (70, 70), interpolation=cv2.INTER_LINEAR)\n",
        "            img_arrays.append([img_sized, label])\n",
        "    return img_arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T04:54:23.644222Z",
          "iopub.status.busy": "2022-03-24T04:54:23.643640Z",
          "iopub.status.idle": "2022-03-24T05:06:02.722062Z",
          "shell.execute_reply": "2022-03-24T05:06:02.721305Z",
          "shell.execute_reply.started": "2022-03-24T04:54:23.644186Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "MfmTCs-DMpVa",
        "outputId": "0e35083a-24bb-408c-d528-d65e1ddfcc39"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a73e50f115cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclass0_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_class0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclass1_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msampled_class1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-1165cca0dcfe>\u001b[0m in \u001b[0;36mget_image_arrays\u001b[0;34m(data, label)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_COLOR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mimg_sized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m70\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_LINEAR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mimg_arrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_sized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg_arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "class0_array = get_image_arrays(sampled_class0, 0)\n",
        "class1_array = get_image_arrays(sampled_class1, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T05:06:02.724154Z",
          "iopub.status.busy": "2022-03-24T05:06:02.723623Z",
          "iopub.status.idle": "2022-03-24T05:06:02.731209Z",
          "shell.execute_reply": "2022-03-24T05:06:02.730391Z",
          "shell.execute_reply.started": "2022-03-24T05:06:02.724116Z"
        },
        "trusted": true,
        "id": "AVd76SaTMpVa"
      },
      "outputs": [],
      "source": [
        "test = cv2.imread('..//IDC_regular_ps50_idx5/13689/1/13689_idx5_x801_y1501_class1.png' ,cv2.IMREAD_COLOR)\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T05:06:02.732916Z",
          "iopub.status.busy": "2022-03-24T05:06:02.732600Z",
          "iopub.status.idle": "2022-03-24T05:06:03.196774Z",
          "shell.execute_reply": "2022-03-24T05:06:03.195997Z",
          "shell.execute_reply.started": "2022-03-24T05:06:02.732873Z"
        },
        "trusted": true,
        "id": "JK3Pkf1zMpVa"
      },
      "outputs": [],
      "source": [
        "combined_data = np.concatenate((class0_array, class1_array))\n",
        "random.seed(41)\n",
        "random.shuffle(combined_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T05:06:03.198468Z",
          "iopub.status.busy": "2022-03-24T05:06:03.198143Z",
          "iopub.status.idle": "2022-03-24T05:06:03.406592Z",
          "shell.execute_reply": "2022-03-24T05:06:03.405901Z",
          "shell.execute_reply.started": "2022-03-24T05:06:03.198432Z"
        },
        "trusted": true,
        "id": "Wkp_TEdJMpVb"
      },
      "outputs": [],
      "source": [
        "X = []\n",
        "y = []\n",
        "\n",
        "for features,label in combined_data:\n",
        "    X.append(features)\n",
        "    y.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T05:06:03.408887Z",
          "iopub.status.busy": "2022-03-24T05:06:03.408656Z",
          "iopub.status.idle": "2022-03-24T05:06:04.257586Z",
          "shell.execute_reply": "2022-03-24T05:06:04.256683Z",
          "shell.execute_reply.started": "2022-03-24T05:06:03.408854Z"
        },
        "trusted": true,
        "id": "3nvD10XWMpVb"
      },
      "outputs": [],
      "source": [
        "X = np.array(X).reshape(-1, 70, 70, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T05:06:04.259277Z",
          "iopub.status.busy": "2022-03-24T05:06:04.259023Z",
          "iopub.status.idle": "2022-03-24T05:06:04.265830Z",
          "shell.execute_reply": "2022-03-24T05:06:04.265001Z",
          "shell.execute_reply.started": "2022-03-24T05:06:04.259241Z"
        },
        "trusted": true,
        "id": "f4OcpWl3MpVb"
      },
      "outputs": [],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T05:19:15.759718Z",
          "iopub.status.busy": "2022-03-24T05:19:15.758683Z",
          "iopub.status.idle": "2022-03-24T05:19:21.219849Z",
          "shell.execute_reply": "2022-03-24T05:19:21.219040Z",
          "shell.execute_reply.started": "2022-03-24T05:19:15.759672Z"
        },
        "trusted": true,
        "id": "oWK4fN7hMpVb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XpKEKhUnMpVc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T05:22:48.998602Z",
          "iopub.status.busy": "2022-03-24T05:22:48.997901Z",
          "iopub.status.idle": "2022-03-24T05:22:49.942318Z",
          "shell.execute_reply": "2022-03-24T05:22:49.940915Z",
          "shell.execute_reply.started": "2022-03-24T05:22:48.998564Z"
        },
        "trusted": true,
        "id": "Lt9pPDQGMpVc"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "for i in range(25):\n",
        "    plt.subplot(5, 5, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_train[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(y_train[i])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-03-24T05:28:52.858989Z",
          "iopub.status.busy": "2022-03-24T05:28:52.858378Z",
          "iopub.status.idle": "2022-03-24T05:28:52.937552Z",
          "shell.execute_reply": "2022-03-24T05:28:52.936365Z",
          "shell.execute_reply.started": "2022-03-24T05:28:52.858870Z"
        },
        "trusted": true,
        "id": "Tbbv-1VKMpVc"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "X_train = X_train / 255\n",
        "X_test = X_test / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZZ9Hoe9MpVd"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Input, Flatten, Dense, Lambda, Reshape\n",
        "from keras.models import Model\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdEX9V-FMpVd"
      },
      "source": [
        "# Variational Autoencoder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t41E29F_MpVe"
      },
      "source": [
        "## Encoder\n",
        "4 conv2d, 1 flatten and 1 dense layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-aRRmCahMpVf"
      },
      "outputs": [],
      "source": [
        "latent_dim = 5 # number of latent dimension parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzDrPFPfMpVf"
      },
      "outputs": [],
      "source": [
        "input_shape = (70, 70, 3)\n",
        "num_channels = 3\n",
        "img_width, img_height = (70, 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1BagafAMpVg"
      },
      "outputs": [],
      "source": [
        "input_img = Input(shape=input_shape, name='encoder_input')\n",
        "\n",
        "x = Conv2D(32, 3, padding='same', activation='relu')(input_img)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu',strides=(2, 2))(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)\n",
        "x = Conv2D(64, 3, padding='same', activation='relu')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1FUGGLQDMpVg"
      },
      "outputs": [],
      "source": [
        "conv_shape = K.int_shape(x) #Shape of conv to be provided to decoder\n",
        "\n",
        "#Flatten\n",
        "x = Flatten()(x)\n",
        "x = Dense(32, activation='relu')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtpZL9nGMpVh"
      },
      "outputs": [],
      "source": [
        "# Two outputs, for latent mean and log variance (std. dev.)\n",
        "\n",
        "z_mu = Dense(latent_dim, name='latent_mu')(x)   #Mean values of encoded input\n",
        "z_sigma = Dense(latent_dim, name='latent_sigma')(x)  #Std dev. (variance) of encoded input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGvoFeFMMpVh"
      },
      "outputs": [],
      "source": [
        "# REPARAMETERIZATION TRICK\n",
        "# Define sampling function to sample from the distribution\n",
        "# Reparameterize sample based on the process defined by Gunderson and Huang\n",
        "# into the shape of: mu + sigma squared x eps\n",
        "#This is to allow gradient descent to allow for gradient estimation accurately. \n",
        "\n",
        "def sample_z(args):\n",
        "  z_mu, z_sigma = args\n",
        "  eps = K.random_normal(shape=(K.shape(z_mu)[0], K.int_shape(z_mu)[1]))\n",
        "  return z_mu + K.exp(z_sigma / 2) * eps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GvO7dmp4MpVh"
      },
      "outputs": [],
      "source": [
        "# sample vector from the latent distribution\n",
        "# z is the labda custom layer we are adding for gradient descent calculations\n",
        "  # using mu and variance (sigma)\n",
        "  \n",
        "z = Lambda(sample_z, output_shape=(latent_dim, ), name='z')([z_mu, z_sigma])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g6i-SAqpMpVh"
      },
      "outputs": [],
      "source": [
        "#Z (lambda layer) will be the last layer in the encoder.\n",
        "# Define and summarize encoder model.\n",
        "\n",
        "encoder = Model(input_img, [z_mu, z_sigma, z], name='encoder')\n",
        "print(encoder.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFfnZHgBMpVi"
      },
      "source": [
        "## Decoder\n",
        "It takes in latent dim as input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3kizlZpTMpVi"
      },
      "outputs": [],
      "source": [
        "decoder_input = Input(shape=(latent_dim, ), name='decoder_input')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y5n4lyEMpVi"
      },
      "source": [
        "Need to start with a shape that can be remapped to original image shape as we want our final output to be same shape original input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PWrNDtvUMpVi"
      },
      "outputs": [],
      "source": [
        "# add dense layer with dimensions that can be reshaped to desired output shape\n",
        "x = Dense(conv_shape[1]*conv_shape[2]*conv_shape[3], activation='relu')(decoder_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktjpB9jrMpVi"
      },
      "outputs": [],
      "source": [
        "# reshape to the shape of last conv. layer in the encoder, so we can \n",
        "x = Reshape((conv_shape[1], conv_shape[2], conv_shape[3]))(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x3i3ixYMpVj"
      },
      "outputs": [],
      "source": [
        "# upscale (conv2D transpose) back to original shape\n",
        "# use Conv2DTranspose to reverse the conv layers defined in the encoder\n",
        "x = Conv2DTranspose(32, 3, padding='same', activation='relu',strides=(2, 2))(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SOzN9K8WMpVj"
      },
      "outputs": [],
      "source": [
        "# Using sigmoid activation\n",
        "x = Conv2DTranspose(num_channels, 3, padding='same', activation='sigmoid', name='decoder_output')(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjRiYRepMpVj"
      },
      "outputs": [],
      "source": [
        "# Define and summarize decoder model\n",
        "decoder = Model(decoder_input, x, name='decoder')\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_THdy4DMpVj"
      },
      "outputs": [],
      "source": [
        "# apply the decoder to the latent sample \n",
        "z_decoded = decoder(z)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRA3XHqqMpVj"
      },
      "source": [
        "VAE is trained using two loss functions reconstruction loss and KL divergence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0S5oxJMZMpVj"
      },
      "outputs": [],
      "source": [
        "# Custome Loss\n",
        "# class to define a custom layer with loss\n",
        "# Loss function = Reconstruction loss + KL divergence loss\n",
        "\n",
        "class CustomLayer(keras.layers.Layer):\n",
        "\n",
        "    def vae_loss(self, x, z_decoded):\n",
        "        x = K.flatten(x)\n",
        "        z_decoded = K.flatten(z_decoded)\n",
        "        \n",
        "        # Reconstruction loss (as we used sigmoid activation we can use binarycrossentropy)\n",
        "        recon_loss = keras.metrics.binary_crossentropy(x, z_decoded)\n",
        "        \n",
        "        # KL divergence\n",
        "        kl_loss = -5e-4 * K.mean(1 + z_sigma - K.square(z_mu) - K.exp(z_sigma), axis=-1)\n",
        "        return K.mean(recon_loss + kl_loss)\n",
        "\n",
        "    # add custom loss to the class\n",
        "    def call(self, inputs):\n",
        "        x = inputs[0]\n",
        "        z_decoded = inputs[1]\n",
        "        loss = self.vae_loss(x, z_decoded)\n",
        "        self.add_loss(loss, inputs=inputs)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqXYL2ILMpVk"
      },
      "outputs": [],
      "source": [
        "# apply the custom loss to the input images and the decoded latent distribution sample\n",
        "y = CustomLayer()([input_img, z_decoded])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzFtinxAMpVk"
      },
      "source": [
        "y is basically the original image after encoding input img to mu, sigma, z and decoding sampled z values.\n",
        "This will be used as output for vae"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCswM5p5MpVk"
      },
      "source": [
        "# VAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nk-JlYpMpVk"
      },
      "outputs": [],
      "source": [
        "vae = Model(input_img, y, name='vae')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xQHrZDNsMpVk"
      },
      "outputs": [],
      "source": [
        "# Compile VAE\n",
        "vae.compile(optimizer='adam', loss=None)\n",
        "vae.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFtvbhSaMpVk"
      },
      "outputs": [],
      "source": [
        "# Train autoencoder\n",
        "vae.fit(X_train, None, epochs = 10, batch_size = 1000, validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rN9ek00MpVl"
      },
      "source": [
        "# Visualize Results\n",
        "Visualize inputs mapped to the Latent space\n",
        "We have encoded inputs to latent space dimension = 5. \n",
        "Extract z_mu --> first parameter in the result of encoder prediction representing mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j4g5AC7bMpVl"
      },
      "outputs": [],
      "source": [
        "mu, _, _ = encoder.predict(X_test)\n",
        "\n",
        "#Plot dim1 and dim2 for mu\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.scatter(mu[:, 0], mu[:, 1], c=y_test, cmap='brg')\n",
        "plt.xlabel('dim 1')\n",
        "plt.ylabel('dim 2')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLhSYjkkMpVl"
      },
      "source": [
        "Visualize images\n",
        "Single decoded image with random input latent vector (of size 1x2)\n",
        "Latent space range is about -5 to 5 so pick random values within this range\n",
        "Try starting with -1, 1 and slowly go up to -1.5, 1.5 and see how it morphs from one image to the other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WxJRJ8nzMpVl"
      },
      "outputs": [],
      "source": [
        "sample_vector = np.array([[1,-1]])\n",
        "decoded_example = decoder.predict(sample_vector)\n",
        "decoded_example_reshaped = decoded_example.reshape(img_width, img_height)\n",
        "plt.imshow(decoded_example_reshaped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5SRiHUpMpVl"
      },
      "outputs": [],
      "source": [
        "n = 20  # generate 15x15 digits\n",
        "figure = np.zeros((img_width * n, img_height * n, num_channels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3bv7lfVMpVl"
      },
      "source": [
        "Let us automate this process by generating multiple images and plotting\n",
        "\n",
        "Use decoder to generate images by tweaking latent variables from the latent space\n",
        "\n",
        "Create a grid of defined size with zeros. \n",
        "\n",
        "Take sample from some defined linear space. In this example range [-4, 4]\n",
        "\n",
        "Feed it to the decoder and update zeros in the figure with output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_YNYRn1UMpVm"
      },
      "outputs": [],
      "source": [
        "# Create a Grid of latent variables, to be provided as inputs to decoder.predict\n",
        "# Creating vectors within range -5 to 5 as that seems to be the range in latent space\n",
        "grid_x = np.linspace(-5, 5, n)\n",
        "grid_y = np.linspace(-5, 5, n)[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_ZhuQfWMpVm"
      },
      "outputs": [],
      "source": [
        "# decoder for each square in the grid\n",
        "for i, yi in enumerate(grid_y):\n",
        "    for j, xi in enumerate(grid_x):\n",
        "        z_sample = np.array([[xi, yi]])\n",
        "        x_decoded = decoder.predict(z_sample)\n",
        "        digit = x_decoded[0].reshape(img_width, img_height, num_channels)\n",
        "        figure[i * img_width: (i + 1) * img_width,\n",
        "               j * img_height: (j + 1) * img_height] = digit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8LobaIHvMpVm"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "#Reshape for visualization\n",
        "fig_shape = np.shape(figure)\n",
        "figure = figure.reshape((fig_shape[0], fig_shape[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTMsQy0BMpVm"
      },
      "outputs": [],
      "source": [
        "plt.imshow(figure, cmap='gnuplot2')\n",
        "plt.show()  "
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "notebook7588f8763a.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}